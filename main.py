from moviepy.editor import (
    VideoFileClip, CompositeVideoClip, concatenate_videoclips,
    ImageClip, AudioFileClip, CompositeAudioClip
)
import numpy as np
import os
import json

from utils.audio_utils import align_segment_to_beat, extract_beats, save_beats
from utils.subtitle_utils import generate_subtitles, overlay_subtitles
from utils.video_effects import add_flash_effect, add_ghost_effect
from utils.video_utils import add_slowmotion, detect_motion_segments, save_segments
from utils.motion_score import compute_motion_score
from utils.text_overlay import create_logo_image
from auto_highlight import classify_motion_segments


def split_into_segments_with_highlight(video_duration, highlights):
    highlights = sorted(highlights)
    segments = []
    prev_end = 0.0

    for start, end in highlights:
        if start > prev_end:
            segments.append((prev_end, start, False))
        segments.append((start, end, True))
        prev_end = end

    if prev_end < video_duration:
        segments.append((prev_end, video_duration, False))

    return segments


if __name__ == "__main__":
    ADD_LOGO = True
    ADD_TEXT = True
    
    audio_path = "sample/input.mp3"
    video_path = "sample/input.mp4"
    os.makedirs("output", exist_ok=True)

    print("ğŸµ åˆ†æç¯€å¥é»ä¸­...")
    beats = extract_beats(audio_path)
    save_beats(beats, "output/beat_times.json")
    print(f"âœ… ç¯€å¥é»å®Œæˆï¼Œå…± {len(beats)} å€‹æ‹é»")

    print("ğŸ¬ åµæ¸¬é«˜å‹•ä½œå€æ®µä¸­...")
    segments = detect_motion_segments(video_path, threshold=3, min_duration=0.2, debug=True)
    save_segments(segments, "output/motion_segments.json")
    print(f"âœ… å‹•ä½œåµæ¸¬å®Œæˆï¼Œå…± {len(segments)} æ®µ")

    if isinstance(segments[0], dict):
        segments = [(float(s["start"]), float(s["end"])) for s in segments]

    aligned_segments = []
    for start, end in segments:
        aligned_start, aligned_end = align_segment_to_beat(start, end, beats)
        aligned_segments.append((aligned_start, aligned_end))
        print(f"ğŸ¯ å°é½Šæ‹é»ï¼š{start:.2f}s â†’ {aligned_start:.2f}s")

    video = VideoFileClip(video_path)
    video_duration = video.duration

    print("ğŸ¯ åˆ†æç²¾å½©åº¦ä¸­...")
    highlight_segments = classify_motion_segments(
        video_path,
        aligned_segments,
        classify_func=lambda p: f"motion ({compute_motion_score(p):.2f})",
        score_threshold=0.5,
    )

    segments_with_flags = split_into_segments_with_highlight(video_duration, highlight_segments)

    for start, end, is_hl in segments_with_flags:
        tag = "ğŸŒŸ" if is_hl else "   "
        print(f"{tag} {start:.2f} ~ {end:.2f}")

    final_clips = []
    for idx, (start, end, is_highlight) in enumerate(segments_with_flags):
        clip = video.subclip(start, end)

        if is_highlight:
            clip_no_audio = clip.without_audio()
            slow_clip = add_slowmotion(clip_no_audio, slow_duration=0.5, speed_factor=0.5)
            
            clip = slow_clip
            
            if ADD_LOGO:
                logo_img = create_logo_image("Timo | AutoCutX", width=300, height=60)
                logo_clip = ImageClip(np.array(logo_img)).set_duration(clip.duration).set_position(("right", "top"))
                clip = CompositeVideoClip([clip, logo_clip])

        final_clips.append(clip)

    if final_clips:
        final_video = concatenate_videoclips(final_clips, method="compose")

        if ADD_TEXT :
            print("ğŸ”¤ è‡ªå‹•ç”¢ç”Ÿå­—å¹•ä¸­...")
            subtitles = generate_subtitles(video_path)
            final_video = overlay_subtitles(final_video, subtitles)

        # âœ… åŠ å…¥å®Œæ•´èƒŒæ™¯éŸ³æ¨‚æ··éŸ³
        print("ğŸ”Š åˆæˆéŸ³è¨Šï¼šèƒŒæ™¯éŸ³æ¨‚ + åŸè²å£“ä½")
        bgm = AudioFileClip(audio_path).volumex(1.0)

        audio_duration = min(final_video.duration, video.audio.duration)
        original_audio = video.audio.subclip(0, audio_duration).volumex(0.4)
        
        mixed_audio = CompositeAudioClip([original_audio, bgm.set_duration(final_video.duration)])
        final_video = final_video.set_audio(mixed_audio)

        final_video.write_videofile(
            "output/final_full_video.mp4",
            codec="libx264",
            preset="ultrafast",
            audio=True,
            ffmpeg_params=[
                "-vf", "scale=iw:ih,setdar=9/16",
                "-aspect", "9:16"
            ]
        )
        print("ğŸ‰ å®Œæ•´å½±ç‰‡å·²ç”¢ç”Ÿï¼")
    else:
        print("âš ï¸ æ²’æœ‰å¯è¼¸å‡ºçš„ç‰‡æ®µã€‚")
